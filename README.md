# malwareDetection

## Objective

The objective is to build a system that can prevent zero day exploits and malwares from causing any damage. This ZDPS/Malware predictor will be based on a machine learning model as there is no way one can foresee an exploit. At the current stage, the product analyses the API calls that a program makes, based on which makes a prediction on whether execution is malicious or benign. Through this method, one can prevent malicious applications from executing, including those that utilize zero day exploits. In this document, we will see why such a system is the best way to implement a ZDPS/Malware predictor, how the model is going to work and what the immediate competition is doing. 

## Dependencies


-   Python >=3.64
-   Keras==2.24
-   TensorFlow==1.14
-   Pandas>=0.24.2
-   Numpy>=1.16
-   Scikit Learn>=0.21
-   Matplotlib
-   Jupyter Notebook>=5.70
-   Flask

## File Structure

- model\_training.ipynb - Main file that trains the ML model and then saves the weights
- predictor.py - Loads the trained model and can submit files for analysis and return the result
- Preprocessing
  - json\_parser.py - Script that collates all the Cuckoo sandbox reports and generates the training/testing dataset
  - Regex.py - Cleans the given dataset so that every call is standardized.
- Server
  - ML.py - the file that takes in an input dataframe and predicts the nature of it
  - actual\_server.py - Opens a socket that receives the API call log from the agent on the target machine
  - \*.txt - Ignore them. Only placeholder texts
  - \*.pickle files are also the same as below
  - Pdf.h5 - The weights for the Keras/TensorFlow model
  - Client
    - Agent.py - Flask Server that takes in a file and then launches NtTrace.
    - Client.py - Sends the call log back to the Host machine (where the ML model is running)
    - NtTrace - Folder that contains NtTrace x86 version
    - templates - Flask files
- Pickle - Folder that contains the weights and mappings of API calls
  - d2.pickle
  - d2\_p2.pickle
  - my\_model.h5

## Getting Started


### Cuckoo Sandbox

One of the main challenges of a project like this is the availability of reliable and good data. The performance of the Machine Learning model will be directly correlated to the data. Hence, it is important for us to focus on this aspect and we chose the Cuckoo Sandbox to generate our datasets and it became the central pivot of our project.

Cuckoo Sandbox allows one to batch analyse a series of files. It stores detailed reports of every files execution which can be used to collate a dataset. Large amounts of data can be produced in this method. However, the process is time consuming. One has to just drop the file onto the Cuckoo web console and it does the rest.

The REST API was also used in the later phase to analyse unknown files during the prediction phase.

Due to the slow nature of analysis that Cuckoo provides, it is only useful during training dataset generation phase and not during the deployed prediction phase. For this reason, the future goal is to create our very own agent that can log API calls any application makes in real time.

### Keras and TensorFlow

TensorFlow and Keras were used as the two main ML frameworks that were used to develop our model. We chose them because they allowed us to rapidly prototype our project and deploy it (testing it) very quickly. To allow a possible later migration to another framework, if at all, we loaded and saved every model using ONNX.

#### model_training.py

The main file that trains the model.

We load the dataset using Pandas as it allows for the most efficient loading of a dataframe without running into memory problems.

![](https://lh6.googleusercontent.com/KeB2OlXJ0lvJDVU-QsFfKLAXy2rLYPcJFmaGfdSNuPAqddpySBWwBiLvJ-xZVPeAlDfoas7jGHhTYbnGLEGYYWoNG2flDhrSg5GA5N3XToIKCF0qkwMJUU2Hov5l_Ok9dcJpO-aG)

The data looks something like this - 

![](https://lh5.googleusercontent.com/tTOCYDi5OV-4p6Vad8XTWKkDvbqd1Wt2uMM4f_rPSCxjLXRZSIB11wd7TpT6Pc3Xq8FIok2vYZNN7i8wYWJDwd4fWahO0NCJPZde44dJN9eajCsDuaU-4xa-0Zbui6uIC0Dteeay)

As Neural Networks can only take as input, numbers (it is math, after all), we would need to replace every API call with a unique ID. I do concede that this method has a flaw, one where the ID might add unintended bias to the network even though it should be considered as inconsequential. I avoided using one-hot encoding as there were too many unique API calls as well as too many columns itself. Besides, we were getting very good results regardless of this.

![](https://lh4.googleusercontent.com/AO8-akxn_poOkrUfHuH5KKYyeEpTWk1O2VTsAayPKmdifS9of-ThGlsVBeA2IfeAorfDYZcAe3FDH6AVzgpO5HzCSE-RXv8qjnH0THr2UfymN-cwzhvgTnBrYBe8WIkAtFyaMB8z)

We save this mapping so that we can use it later in the prediction phase as well. The best way to do that is usually pickling the mappings as they are then stored as serialised binary files.

![](https://lh6.googleusercontent.com/2vhiR50xjGNoUC3pecijsq3C3oc_tjPJtqQWZwrbGpmdp2dYfhC46eIs_WX_tGhGXepDY-5_UlzxwixzEzUlgyXNG-B5ZsdY7l9NPmtKaFhKrh6fTBdFshrP_7Z49oxKlQcmL6YY)

We then train the model. Saving it for later use.

![](https://lh4.googleusercontent.com/g4sS6U7NGD5mt_2XpOlh2VZKrRE3a8Ud4Ai5pwbtcSIadePT7f1eTd4U5drNTdeSxaAU_MFveWBk8hHd3Tzjw4qMIXwBChnRF1w6kQS7PCfRm_bx75jqpBOL4-zvT_TnxzPJ34Cs)

#### Prediction.py

This script allows one to submit a file for analysis and then it returns the probability of it being safe.

We first connect to the sandbox using Cuckoo's REST API. We take the file and then submit it for analysis.

![](https://lh6.googleusercontent.com/vlsACXu38wxAoVIOMkb7wbH9IGlrkuZtIWlO5vd9LApDMyat9DuRszFTRZ_uYDcA0n5_5eNV94-AFDGTKMB1_NfARYGteJOddraQ7k03dfX0lJ9t46mBpCNqGBHaQzFXmUIm3LRb)

After the report has been generated, we fetch it using the same API.

![](https://lh3.googleusercontent.com/RaBkImW0YVDLIpglHYER9VxLtYPq9scEqmhCMHPdetCSicKA3zogITKcqzTkUkTq4HkR6wadExcoRlvruhHqBOEegpvPU1oyyMYrpi9285LTdlj5B211WmEUZY0fQpI3bauzApuQ)

Using the JSON report, we parse it to create a dataframe with only relevant infromation that our model needs. We then use it to make a prediction.

![](https://lh5.googleusercontent.com/zyjHMrLXBmQG48wrbuayJXPyQlN9N4DvJaICmcRNm8rGtebEdL5IscWuk2lanv4YScUIrhFCW8cXuUPeXfZzWE5gfH0KP_sAg87RbhVd_6aBha5Rr0Pm_E7apGeM_jI1xi3GhTnD)


## Future

Hopefully, our application follows this structure as it develops

![](https://i.imgur.com/KG7Pviw.png)

## References
1. Our dataset - https://bit.ly/323wRsS
2. Dataset - Youngjoon Ki, Eunjin Kim, and Huy Kang Kim, “A Novel Approach to Detect Malware Based on API Call Sequence Analysis,” International Journal of Distributed Sensor Networks, vol. 2015, Article ID 659101, 9 pages, 2015. doi:10.1155/2015/659101
